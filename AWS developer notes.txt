1. EC2 instance storage:(72)

EBS: 
elastic block store volume is a network drive attaches to instances.
persist data even after their termination and can be mounted to one instace (ccp) but at developer level multi attach feature is there.
locked to one az if want to move use snapshot
to use we need to provide the capacity like GBs and IOPS

by default if rooted EBS is deleted on termination where other attached EBS vols are not deleted.

EBS Snapshots:
Backup for EBS , is incremental backup , can copy across az or region 
features: 
1. EBS Snapshot Archive: archive tier(75% cheaper) takes 24-72 hrs to restore
2. Recycle Bin: recycle bin for accidental deletion and retention is 1day-1yr
3. Fast Snapshot Restore(FSR): force full initialization of snapshot for no latency on first use(expensive)

AMI(Amazon Machine Image):
customization of ec2 instance, can add our software, config., OS, monitoring.,etc. Faster boot/config. time because all software is pre-packaged.
built for specific region( copied across regions)
launch ec2 intances from public AMI, our own AMI , our AWS Marketplace AMI

process: start ec2 and customize, stop instance(for data integrity), Build an AMI(creates snapshots), launches instances from other AMIs

EC2 instance store:
high-performance hardware disk, better I/O performance, if instance is stopped they will loss their storage, use as buffer/cache/scratch data/temporary content, risk of data loss if hardware fails, backups and replication are our responsiblility.

EBS Volume types(6 types):
--------------------------------------
GP ( general purpose SSD volume balances price and perf.) 
-cost effective, low latency 
-1 GiB - 16 TiB
-system boot vols, virtual desktops, dev and test envs

1. gp2(SSD): 
small gp2 vol can burst IOPS to 3,000,
size of vol and IOPS are linked, max is 16,000
3 IOPS per GB, means 5,334 GB we are at max IOPS

2. gp3(SSD): 
baseline 3,000 IOPS and throughput 125 MiB/s
can increase 16,000 IOPS and throughput upto 1000 MiB/s independently
---------------------------------
Provisioned IOPS(PIOPS)(highest perf. SSD vol for mission critical low latency or high throughput workloads)
-apps that need more than 16000 IOPS
- great for database workloads (sensitive to storage perf and consistency)

3. io 1:(4GiB - 16 TiB)
max PIOPS 64,000 for nitro instances and 32,000 for other
increase PIOPS independently,more durability and more IOPS per GiB

4. io 2:( 4 GiB - 64 TiB)
sub-millisecond latency 
max PIOPS 256,000 with IOPS:GiB is 1,000:1
-----------------------------------------------------
(Low cost HDD )
can't be used for boot vol
125 GiB - 16 TiB

5. st 1:(frequently accessed) throughput optimized 
Big data, data warehouses, log processing 
max throughput 500 MiB/s, max IOPS 500

6. sc 1: (less freq. accessed) Cold HDD
lowest cost
max throughput 250 MiB/s, max IOPS 250
--------------------------------------------
EBS Multi-Attach :
for only provisioned iops family io1,io2
attach same EBS vol to multiple ec2 instances in same AZ
each instance has full read& write permissions to high-perf. vol
use case: achieve high application availability in clustered linux apps(eg: teradata)
	applications must manage concurrent write ops.
upto 16 instances only at a time	
file system must be cluster-aware (not XFS, EXT4)


Amazon EFS- Elastic File System
Managed NFS (network file system) can be mounted to many eC2
EFS works with instances in multi-AZ
highly available, scalable , expensive(3x gp2), pay per use
use cases: content management , web serving, data sharing, Wordpress
uses interanl NFSv4 protocol
uses security grp to control access to EFS
compatible with linux based AMIs(not windows)
POSIX file system(linux) that has std file API

EFS scale: 1000s of concurrent NFS client, 10 GB+/s throughput
grow petabyte scale nfs automatically 

performance Mode(set at EFS creation time)
general purpose(default): latency sensitive use cases (webservers, CMS etc)
max I/O-higher latency,throughput,highly parallel(bigdata,media processing)

throughput Mode:
Bursting: 1 TB= 50 MiB/s + burst of 100 MiB/s
Provisioned: set throughput regardless storage size(eg:1 GiB/s for 1 Tb storage)
Elastic:  automatically scales up and down based on workloads
upto 3 GiB/s for reads and 1 GiB/s for write 
used for unpredictable workloads

EFS- storage classes
storage Tiers ( lifecycle management feature- move file after N days)
std : for freq. access
infreq access (EFS-IA): cost to retrieve files, lower price to store, enable EFS-IA with lifecycle policy

availability and durability:
std: multi az, great for prod
one zone : one Az, grear for dev, back enabled by default, compatible with IA(EFS One Zone-IA) 
90% in cost savings


EBS vs EFS 

EBS: one instance at time( except io1& io2)
locked at az level, gp2: increases IO if disk size increases, gp3: IO can increased independently
to migrate across az: need snapshots and restore at respective az , don't backup while application is handling lot of traffic.

EFS: mounted to 100s of instances across az, EFS share website files (wordpress), only for linux instances, costly than EBS, can leverage EFS-IA for cost savingsf
==============================================================================================
2. AWS Fundamentals: ELB+ASG(95)

scalability: by adapting the application can handle greater loads
a. vertical scalability(increase size)
for non distributed systems like databases like RDS , ElastiCache can scale vertically 

b. horizontal scalability(increase number)(elasticity)
for distributed systems, common web apps/modern apps

High Availability
having application at least 2 Azs, to survive a data center loss, can be passive for RDS Multi-Az and active for horizontal scaling

Load balancing:
servers that forward traffic to multiple servers downstream

ELB(Elastic Load Balancer):
managed load balancer, aws takes care of upgrades, maintenance, high availability and few config. knobs
if we have our own LB but it will cost less but will be alot more effort on our end
it's integrated with many aws services like ec2, ASG, ECS, ACM,CloudWatch, Route 53, WAF,AWS Global Accelerator

Health Checks:(crucial for Load balancers)
enable LB to know if instances it forwards traffic to are available to reply to request and it's done on a port and route 

Types of load balancers
Classic LB: old generation-2009: HTTP,HTTPS,TCP,SSL(Secure TCP)
Application LB: new -2016: HTTP,HTTPS,WebSocket
Network LB:new-2017: TCP, TLS(secure TCP), UDP
Gateway LB:2020:Operates at layer 3 (network)- IP protocol

Application Load Balancer (ALB) layer 7(HTTP)
-load balancing to multiple HTTP apps across machines(target grps)
-load balancing to multiple apps on the same machine (eg:containers)
-support for HTTP/2 and WebSocket
-support redirects ( from HTTP to HTTPS for eg)

Routing tables to diff target grps:
routing based on : 
	-path in url(example.com/users & example.com/posts)
	-hostname in url (one.example.com & other.example.com)
	-Query String,Headers (example.com/users?id=123&order=false)
ALB are great fit for microservices & container-based apps (docker & ECS)
has port mapping feature to redirect to a dynamic port in ECS

ALB target grps:
ec2 instances ( managed by ASG) -HTTP
ECS tasks( managed by ECS itself)- HTTP
lambda fns - HTTP req is translated into JSON event 
IP Address-must be private IP's 
ALB can route to multi target grps
Health checks are at target grp level

while connecting through ALB from client to instance
client Ip can't be known by instance instead its knows ip which is private ip fo ALB
if want know the ip of client it will look into extra headers in HTTP req which are port and proto (x-forward-for)

Network Load Balancer (NLB) (layer 4) allows
-forward TCP & UDP traffic to instances
-Handle millions of req per sec
-less latency 100ms(400ms for ALB)
one static IP per Az and supports assigning Elastic IP 
used for extreme performance, TCP or UDP traffic

NLB targets grps: ec2 instances, IP addressess(private), ALB
Health checks support TCP, HTTP & HTTPS

Gateway Load Balancer(GLB)(layer 3)Network layer
deploy,scale & manage a fleet of 3rd party network virtual appliances in aws
eg: firewalls, intrusion detection & prevention sys,deep packet inspection sys,payload manipulation
combines: transparent network gateway: single entry/exti for all traffic
	  Load balancer: distributes traffic to our virtual appliances
- uses the GENEVE protocol on port 6081

Sticky Sessions: 
stickiness so that same client is always redirects to the same instance behind a load balancer 
works for CLB,ALB,NLB
cookie is used for expiration date of control
to dont't lose the session data
Application-based cookies:
custom cookie : generated by us (don't us names AWSALB,AWSALBAPP,AWSALBTG)
application : generated by LB
Duration-based cookie:generated by cookie for a period of time


Cross-Zone load balancing
ALB:enabled by default(disabled at target grp) and no charge
NLB&GLB: disabled by default, charges for inter AZ data if enabled
CLB:disabled by default, no charges if enabled

SSL/TLS (Secure Sockets Layer/Transport Layer Security(new))
SSL certficate allows traffic between clients and load balancer to be encrypted in transit.
-is issued by Certificate Authorities(CA)
-Comodo,Symantec,GoDaddy,GlobalSign,Digicert etc..
-load balancer uses X.509 certificate 
-manage certificates using ACM(aws certificate manager)
-can create own certificates also
-HTTPS listener: 
specify default certificate 
can add optional list of certificates to support multiple domains
-clients use SNI(Server Name Indication)to specify the hostname they reach

Sever Name Indication (SNI)
solves the problem of loading multiple SSL certificates onto the webserver (to serve multiple websites)
newer protocol and requires the client to indicate the hostname of the target server in the initial SSL handshake 
server will find correct cert or return the default one 
-only works for ALB & NLB 

Connection draining(CLB)/Deregrestration Delay(ALB&NLB):
time to complete "in flight requests" while the instance is de-registering or unhealthy
-stops sending new reqs to that instance 
between 1 to 3600 seconds (def : 300 seonds)
set to low value if req is short

Auto Scaling Group(ASG)
-scale out(add instances) when increased load and scale in (remove instances) when decreased load.
-will have maxi and mini number of instances running 
-recreate the instance incase one is unhealthy
-free
-attribute of ASG , a launch template which has AMI+Instance type, ec2 user data, EBS volumes, Security grps, SSH key pairs, IAM roles for instances, Network+Subnet information and Load Balancer information
- can also be integrated with CloudWatch by triggering the alarms to scale respectively.

ASG - dynamic scaling policies
target tracking scaling :most simple and easy 
simple/step scaling:add and remove based on trigger of cloudwatch alarms 
scheduled actions: anticipate a scaling on known usage patterns
predictive scaling: continously forecast load and schedule scaling ahead
good metrics to scale on: CPUUtilization , RequestCountPerTarget, Average Network In/out

ASG scaling cooldowns
after scaling activity we are in a cooldown period of 300 sec
during this ASG will not launch or terminate additional instances

ASG Instance Refresh
to update launch template and then recreate all ec2 instances 
we can use native feature of instance refresh and setting of minimum healthy percentage like 60%

-------------------------------------------------------------------------------------------------------------------------------------------------------
Amazon RDS (slide: 138)
relational database (managed database) uses SQL query language 
has postgres, mysql, MariaDb, Oracle, Microsoft SQL server, Aurora
-automated provisioning, OS patching
-continuonus backups and restore to specific timestamp
-Monitoring dashboards
-Read Replicas for improved read perform
-Mutli az setup for disaster recovery
-Maintenance windows for upgrades
-Scaling capability
-Storage backed by EBS(gp2 or io1)
-we can't SSH into instances cause RDS is managed service

RDS -storage auto scaling
-when RDS detects running out of free database storage, it scales automatically
-can set maximum storage threshold 
-automatically modify storage if: 
	-free storage is less than 10% of allocated storage
	-low-storage lasts at least 5 min 
	-6 hrs have passed since last modification
- uses for unpredictable workloads

RDS read replicas:
upto 15
within az, cross az, cross region 
replication is ASYNC so reads eventually cosistent
replicas can be promoted to their own DB
read replicas ae used for SELECT only kind of statements (not INSERT, DELETE, UPDATE)
in aws there's a network cost when data goes from one az to other 
- for RDS read replicas within same region, we don't pay any

RDS Multi Az(Disaster Recovery)
SYNC replication
one DNS name -automatic app failover to standby
increase availability
not used for scaling 
- read replicas can also be setup as Multi Az for disaster recovery 
- if single az to multi az: zero downtime operation, just click on modify and following happens interally:
	-a snapshot is taken
	-a new DB is restored from the snapshot in new AZ
	-Synchronization is established between the two databases

Amazon Aurora (slide 147)

proprietary technology from AWS (not opensourced)
Postgres (3x) and MySQL(5x) are supported and have improve performance of RDS
automatically grows in increaments of 10GB to 128TB
have upto 15 replicas and replication processs is faster than MySQL

Aurora high availability and read scaling
6 copies of data across 3 az:
4 copies of 6 for writes , 3copies of 6 for reads 
self healing .storage is striped across 100s of vols
one master writes+ 15 read replics(upto)
automated failover for master in less than 30 sec
support cross region replication

will have two endpoints 
Writer endpoint to master 
Reader endpoint( with load balancer at connection level ) to read replicas with auto scaling

RDS & Aurora Security
at rest:
databases master & replicas encryption using KMS (defined at launch time)
if master is not encrypted, the read replicas cannot be encrypted
to encrypt an un-encrypted database, go through snapshot & restore as encrypted

in flight:
TLS- ready by default, use the AWS TLS root certifcates client side
IAM authentication: by iam roles 
security grps: control network access to RDS (block or allow ip,security grps, ports)
No SSH except for RDS Custom 
Audit logs can enabled and sent to CloudWatch Logs for longer retention

Amazon RDS Proxy:
full managed database proxy for RDS
allows apps to pool and share DB connections established with database
improves database efficiency by reducing stress on database resources and minimize open connections ( and timeouts)
serverless(integrity with lambdas),autoscaling highly avialable(multi az)
reduced RDS & Aurora failover time (66%) using proxy
enforce IAM authentication for DB, and securely store credentials in Secrets Manager
RDS proxy is never publicy accessible ( only by VPC)
 
Amazon ElasticCache 
managed Redis or Memcached
in-memory databases with high performance, low latency
reduces load off of databases for read intensive workloads, makes app stateless
REDIS : multi az , read replicas, data durability using AOF persistence,Backup and restore, supports sets and sorted sets

MEMCACHED : multi-node of partitioning of data(sharding),no high avail, non persistent, no backup and restore, multi-thread architecture

caching strategies
Lazy loading/ cache-side/lazy population:
pros: only req data is cached and node failure are not fatal 
cons: 
	cache miss penalty that results 3 round trips, noticeable delay for that req, 
	stale data: data can be updated in the database and outdated in the cache

Write Through-add or update cache when database is updated:
pros: data in cache is never stale, reads are quick  and write penalty vs read penalty(each write requires 2 calls)
cons: missing data until it is added/updated in the DB. Mitigatin is to implement Lazy Loading strategy as well

Cache Evictions and Time-to-live(TTL)
cache eviction can occur in three ways:
you delete the item explictly in the cache
item is evicted because the memory is full and it's not recently used(LRU)
you set an item time-to-live(TTL)
-TTL are good for leaderboards, comments,activity streams
-TTL can range from few seconds to hours or days
 
Amazon MemoryDB for Redis
Redis-compatible, durable.in-memory database service
ultra fast performance with 160 millions of req/second
durable in-memory data storage with multi az transactional log
scale seamlessly from 10s GBs to 100s TBs of storage 
use cases: web and mobile apps, online gaming, media streaming





